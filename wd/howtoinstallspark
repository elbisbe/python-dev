

## Step 1: Download Apache Spark 3.0.1
1. `curl -L -s https://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz | tar xvz -C /workspace/example-Apache-Spark-and-DataStax-Astra/Connect`

## Step 2: Run Apache Spark in standalone cluster mode with 1 worker
1. If not already: `cd Connect`
2. `cd spark-3.0.1-bin-hadoop2.7`
3. `./sbin/start-master.sh`
4. `./sbin/start-slave.sh <master-url>`
    - To the find the master url in Gitpod, open port `8080` in a new browser and copy and paste the master url into the designated spot

## Step 5: Run Spark-Shell and connect to our Astra database
1. If not already: `cd spark-3.0.1-bin-hadoop2.7`

./bin/spark-shell
--master {master-url} 

# Other stuff
--files /workspace/example-Apache-Spark-and-DataStax-Astra/Connect/secure-connect-{your-db-name}.zip \
--conf spark.cassandra.connection.config.cloud.path=secure-connect-{your-db-name}.zip \
--conf spark.cassandra.auth.username={Client ID} \
--conf spark.cassandra.auth.password={Client Secret} \
--conf spark.sql.extensions=com.datastax.spark.connector.CassandraSparkExtensions
~~~
  
## Step 6: Test if Spark Connected to DataStax Astra
1. You can run one or both, within the Spark-Shell to test the connection:
~~~
import org.apache.spark.sql.cassandra._
val data = spark.read.cassandraFormat("leaves", "{your-keyspace}").load
data.printSchema
data.show
~~~
AND / OR
~~~
spark.conf.set(s"spark.sql.catalog.mycatalog", "com.datastax.spark.connector.datasource.CassandraCatalog")
spark.sql("SHOW TABLES FROM mycatalog.{your-keyspace};").show
spark.sql("use mycatalog.{your-keyspace};")
spark.sql("select * from leaves").show
~~~

## Additional Resources

- If you want to watch how to do this in a live demonstration, check out this [YouTube Video](https://youtu.be/sCh07TeUWpk)
- Check out this accompanying [blog](https://blog.anant.us/connect-apache-spark-and-datastax-astra/) as well!
